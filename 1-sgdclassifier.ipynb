{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confirmed-alpha",
   "metadata": {},
   "source": [
    "# LAB 7: Error analysis\n",
    "\n",
    "Objectives\n",
    "* Construct a  linear text classifier using SGDClassifier\n",
    "* Evaluate its performance and categorize the errors that it makes\n",
    "* Eaxmine model's coefficients and decision function values\n",
    "* Interpret model results using LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "existing-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-support",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dynamic-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\n",
    "    \"s3://ling583/lab7-train.parquet\", storage_options={\"anon\": True}\n",
    ")\n",
    "test = pd.read_parquet(\"s3://ling583/lab7-test.parquet\", storage_options={\"anon\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aggressive-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\n",
    "    \"en_core_web_sm\",\n",
    "    exclude=[\"tagger\", \"parser\", \"ner\", \"lemmatizer\", \"attribute_ruler\"],\n",
    ")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp.tokenizer(text)\n",
    "    return [t.norm_ for t in doc if not (t.is_space or t.is_punct or t.like_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "circular-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stock-appreciation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1d0ccd43414d0ca4ed44fcc4c7caf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19054 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3ae6cd16e04b4897eb0cc182ebc280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mp.Pool() as p:\n",
    "    train[\"tokens\"] = pd.Series(p.imap(tokenize, tqdm(train[\"text\"]), chunksize=100))\n",
    "    test[\"tokens\"] = pd.Series(p.imap(tokenize, tqdm(test[\"text\"]), chunksize=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-automation",
   "metadata": {},
   "source": [
    "The labels are: GPOL = domestic politics, GSPO = sports, GVIO = war/civil war, GJOB = labor issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "characteristic-competition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPOL    7410\n",
       "GSPO    5639\n",
       "GVIO    3712\n",
       "GJOB    2293\n",
       "Name: topics, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"topics\"].value_counts()\n",
    "#GPOL Politics    \n",
    "#GSPO Sports\n",
    "#GVIO Violence - War/ Civil war\n",
    "#GJOB labor issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-accommodation",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Baseline classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "moderate-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ranging-stream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        GJOB       0.94      0.94      0.94       573\n",
      "        GPOL       0.95      0.93      0.94      1853\n",
      "        GSPO       0.99      0.99      0.99      1410\n",
      "        GVIO       0.88      0.91      0.89       928\n",
      "\n",
      "    accuracy                           0.95      4764\n",
      "   macro avg       0.94      0.94      0.94      4764\n",
      "weighted avg       0.95      0.95      0.95      4764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline = make_pipeline(CountVectorizer(analyzer=identity), SGDClassifier())\n",
    "baseline.fit(train[\"tokens\"], train[\"topics\"])\n",
    "base_predicted = baseline.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"topics\"], base_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-study",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Hyperparameter search\n",
    "\n",
    "Find an optimal set of hyperparameters for a Tfidf+SGDClassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "annual-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from dask_ml.model_selection import RandomizedSearchCV\n",
    "from logger import log_search\n",
    "from scipy.stats.distributions import loguniform, randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "boolean-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "loved-magic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:46331</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.62 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:46331' processes=4 threads=4, memory=16.62 GB>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://127.0.0.1:46331\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "binary-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"lab-7\")\n",
    "sgd = make_pipeline(\n",
    "    CountVectorizer(analyzer=identity), TfidfTransformer(), SGDClassifier()\n",
    ")\n",
    "# Skeleton classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "editorial-adams",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 s, sys: 1.39 s, total: 11.4 s\n",
      "Wall time: 3min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    sgd,\n",
    "    {\n",
    "        \"countvectorizer__min_df\": randint(1, 20),\n",
    "        \"countvectorizer__max_df\": uniform(0.5, 0.5),\n",
    "        \"tfidftransformer__use_idf\": [True, False],\n",
    "        \"sgdclassifier__alpha\": loguniform(1e-6, 1e-2),\n",
    "    },\n",
    "    n_iter=50,\n",
    "    scoring=\"f1_macro\",\n",
    ")\n",
    "search.fit(train[\"tokens\"], train[\"topics\"])\n",
    "log_search(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-magazine",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Compare optimized model to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "intended-andrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        GJOB       0.98      0.93      0.95       573\n",
      "        GPOL       0.94      0.97      0.95      1853\n",
      "        GSPO       1.00      1.00      1.00      1410\n",
      "        GVIO       0.93      0.90      0.91       928\n",
      "\n",
      "    accuracy                           0.96      4764\n",
      "   macro avg       0.96      0.95      0.95      4764\n",
      "weighted avg       0.96      0.96      0.96      4764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = make_pipeline(\n",
    "    CountVectorizer(analyzer=identity, min_df=5, max_df=0.75),\n",
    "    TfidfTransformer(use_idf=True),\n",
    "    SGDClassifier(alpha=1e-4),\n",
    ")\n",
    "sgd.fit(train[\"tokens\"], train[\"topics\"])\n",
    "predicted = sgd.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"topics\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "falling-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_f1 = f1_score(test[\"topics\"], base_predicted, average=\"macro\")\n",
    "sgd_f1 = f1_score(test[\"topics\"], predicted, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "extended-hostel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base F1 score: 0.9426472666025926\n",
      "SGD F1 score:  0.954526192005073\n",
      "Difference:    0.011878925402480478\n"
     ]
    }
   ],
   "source": [
    "print(f\"Base F1 score: {base_f1}\")\n",
    "print(f\"SGD F1 score:  {sgd_f1}\")\n",
    "print(f\"Difference:    {sgd_f1 - base_f1}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "committed-float",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20712047532537398"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sgd_f1 - base_f1) / (1 - base_f1)\n",
    "# Percentage error reduction; how much we imroved over the base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "frequent-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom_test, wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "included-banks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD and baseline agreed 4610 times\n",
      "SGD was right, and baseline was wrong 105 times\n",
      "Baseline was right, and SGD was wrong 49 times\n"
     ]
    }
   ],
   "source": [
    "# Predicted is the SGD prediction\n",
    "# test[\"topics\"] is the right answer\n",
    "# if they are equal, the value is true, if they are not, then it is false\n",
    "diff = (predicted == test[\"topics\"]).astype(int) - (base_predicted == test[\"topics\"]).astype(int)\n",
    "# if both base and SGD have the same answer, thehn we get 0\n",
    "# If baseline was wrong (0) and SGD was right(1) we get 1\n",
    "# If baseline was right (1) and SGD was wrong (0) we get -1\n",
    "\n",
    "print(f\"SGD and baseline agreed {sum(diff == 0)} times\")\n",
    "print(f\"SGD was right, and baseline was wrong {sum(diff == 1)} times\")\n",
    "print(f\"Baseline was right, and SGD was wrong {sum(diff == -1)} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "logical-charter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.750695876493649e-06"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for those that were classified differently by the two classifiers, they theoretically have a 50/50 \n",
    "# chance to get into either classifier. We run the binomial test to see if the distribution of these\n",
    "# choices matches with that assumption.\n",
    "\n",
    "binom_test([sum(diff == 1), sum(diff == -1)], alternative=\"greater\")\n",
    "\n",
    "# the result, approximately 0.000000375 is much lower that the standard 0.05 alpha for the test\n",
    "# this just means that in the case of a true 50/50 chance scenario, the probability of achieving the same outcome as above is \n",
    "# incredibly small. This would indicate that the SGD classifier actually is better than the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aquatic-surprise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=8137.5, pvalue=3.2017563999193402e-06)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar to the binomial test above.\n",
    "# is only really applicable when you only care about the sign, plus or minus\n",
    "wilcoxon(diff, alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-communist",
   "metadata": {},
   "source": [
    "**TO DO:** Summarize your results: how much better is the optimized model? Is it significantly better than the baseline?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-visitor",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sexual-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "maritime-notice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        GJOB       0.97      0.94      0.96       573\n",
      "        GPOL       0.94      0.96      0.95      1853\n",
      "        GSPO       1.00      0.99      1.00      1410\n",
      "        GVIO       0.92      0.91      0.92       928\n",
      "\n",
      "    accuracy                           0.96      4764\n",
      "   macro avg       0.96      0.95      0.96      4764\n",
      "weighted avg       0.96      0.96      0.96      4764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In this version we change the preprocessor portion and add a tokenizer\n",
    "sgd = make_pipeline(\n",
    "    CountVectorizer(preprocessor=identity, tokenizer=tokenize, min_df=5, max_df=0.75),\n",
    "    TfidfTransformer(use_idf=True),\n",
    "    SGDClassifier(alpha=1e-4),\n",
    ")\n",
    "sgd.fit(train[\"text\"], train[\"topics\"])\n",
    "predicted = sgd.predict(test[\"text\"])\n",
    "print(classification_report(test[\"topics\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "moral-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The built in pickle function does not work with these complicated structures so we use cloudpickle\n",
    "cloudpickle.dump(sgd, open(\"sgd.model\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-desire",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
